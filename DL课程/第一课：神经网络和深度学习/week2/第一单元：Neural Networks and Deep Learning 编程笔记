
第一课第二周程序笔记：
一、对数据的预处理：
Common steps for pre-processing a new dataset are:

1.Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, ...)
2.Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)
3."Standardize" the data

二、General Architecture of the learning algorithm
Key steps: In this exercise, you will carry out the following steps:

- Initialize the parameters of the model
- Learn the parameters for the model by minimizing the cost  
- Use the learned parameters to make predictions (on the test set)
- Analyse the results and conclude
三、 Building the parts of our algorithm
1.Define the model structure (such as number of input features)
2.Initialize the model's parameters
3.Loop:
   - Calculate current loss (forward propagation)
   - Calculate current gradient (backward propagation)
   - Update parameters (gradient descent)
You often build 1-3 separately and integrate them into one function we call model().



What to remember: You've implemented several functions that:

Initialize (w,b)
Optimize the loss iteratively to learn parameters (w,b):
computing the cost and its gradient
updating the parameters using gradient descent
Use the learned (w,b) to predict the labels for a given set of examples